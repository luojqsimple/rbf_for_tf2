from keras.initializers import Initializer
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from keras import backend as K
from keras.layers import Layer
from keras.initializers import RandomUniform, Constant
import numpy as np

from keras.models import Sequential
from keras.layers import Dense
from keras.losses import binary_crossentropy
from keras.optimizers import Adam


# kmeans layer
class InitCentersKMeans(Initializer):
    """Initializer for initialization of centers of RBF network
        by clustering the given data set.
    # Arguments
        X: matrix, dataset
    """

    def __init__(self, X, max_iter=100):
        self.X = X
        self.max_iter = max_iter

    def __call__(self, shape, dtype=None):
        assert shape[1] == self.X.shape[1]

        n_centers = shape[0]
        km = KMeans(n_clusters=n_centers, max_iter=self.max_iter, verbose=0)
        km.fit(self.X)
        return km.cluster_centers_


# RBF layer
class RBFLayer(Layer):
    def __init__(self, output_dim, initializer=None, betas=1.0, **kwargs):
        self.output_dim = output_dim
        self.init_betas = betas
        if not initializer:
            self.initializer = RandomUniform(0.0, 1.0)
        else:
            self.initializer = initializer
        super(RBFLayer, self).__init__(**kwargs)

    def build(self, input_shape):

        self.centers = self.add_weight(
            name="centers",
            shape=(self.output_dim, input_shape[1]),
            initializer=self.initializer,
            trainable=True,
        )
        self.betas = self.add_weight(
            name="betas",
            shape=(self.output_dim,),
            initializer=Constant(value=self.init_betas),
            trainable=True,
        )

        super(RBFLayer, self).build(input_shape)

    def call(self, x):
        C = K.expand_dims(self.centers)
        XC = K.transpose(K.transpose(x) - C)
        D = K.expand_dims(K.sqrt(K.mean(XC**2, axis=0)), 0)
        H = XC / D
        return K.exp(-self.betas * K.sum(H**2, axis=1))

    def compute_output_shape(self, input_shape):
        return (input_shape[0], self.output_dim)

    def get_config(self):
        # have to define get_config to be able to use model_from_json
        config = {"output_dim": self.output_dim}
        base_config = super(RBFLayer, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))


def maxminnorm(array):
    maxcols = array.max(axis=0)
    mincols = array.min(axis=0)
    data_shape = array.shape
    data_rows = data_shape[0]
    data_cols = data_shape[1]
    t = np.empty((data_rows, data_cols))
    for i in range(data_cols):
        t[:, i] = (array[:, i] - mincols[i]) / (maxcols[i] - mincols[i])
    return t


# create dataset
# reference https://zhuanlan.zhihu.com/p/36982945
def test_data1(sample_number=1000):
    # 随机从高斯分布中生成两个数据集
    mean0 = [2, 7]
    cov = np.mat([[1, 0], [0, 2]])
    data1 = np.random.multivariate_normal(mean0, cov, sample_number)
    mean1 = [8, 3]
    cov = np.mat([[1, 0], [0, 2]])
    data2 = np.random.multivariate_normal(mean1, cov, sample_number)
    y1 = np.zeros((sample_number, 1))  # 第一类，标签为0
    y2 = np.ones((sample_number, 1))  # 第二类类，标签为1
    train_data = np.vstack((data1, data2))
    train_label = np.vstack((y1, y2))
    shuffle_idx = np.arange(sample_number * 2)
    np.random.shuffle(shuffle_idx)
    train_data = train_data[shuffle_idx]
    train_label = train_label[shuffle_idx]
    return train_data, train_label


# create dataset
# reference https://zhuanlan.zhihu.com/p/36982945
def test_data2(sample_number=1000):
    # 随机均匀分布中生成数据
    all_data = np.random.rand(sample_number * 2, 2)
    data1 = all_data[all_data[..., 0] > all_data[..., 1]]
    data2 = all_data[all_data[..., 0] <= all_data[..., 1]]
    y1 = np.zeros((sample_number, 1))  # 第一类，标签为0
    y2 = np.ones((sample_number, 1))  # 第二类类，标签为1

    train_data = np.vstack((data1, data2))
    train_label = np.vstack((y1, y2))

    shuffle_idx = np.arange(sample_number * 2)
    np.random.shuffle(shuffle_idx)

    train_data = train_data[shuffle_idx]
    train_label = train_label[shuffle_idx]
    return train_data, train_label


samples_num = 3000
train_data, train_label = test_data2(samples_num)
plt.scatter(
    train_data[np.argwhere(train_label == 0), 0],
    train_data[np.argwhere(train_label == 0), 1],
    s=5,
    c="b",
)
plt.scatter(
    train_data[np.argwhere(train_label == 1), 0],
    train_data[np.argwhere(train_label == 1), 1],
    s=5,
    c="g",
)

model = Sequential()
rbflayer = RBFLayer(
    10, initializer=InitCentersKMeans(train_data), betas=2.0, input_shape=(2,)
)
model.add(rbflayer)
model.add(Dense(1, activation="sigmoid"))
model.compile(loss=binary_crossentropy, optimizer=Adam(), metrics=["accuracy"])
model.fit(train_data, train_label, epochs=1000)


# x1 = np.linspace(-2,12,1000)
# x2 = np.linspace(-2,12,1000)
# test_x = np.vstack((x1,x2)).T

test_x, _ = test_data1()
test_x = maxminnorm(test_x)

test_y = model.predict(test_x)

plt.figure(figsize=(16, 16))
# plot the train data
plt.scatter(
    train_data[np.argwhere(train_label == 0), 0],
    train_data[np.argwhere(train_label == 0), 1],
    s=5,
    c="b",
    marker="x",
)
plt.scatter(
    train_data[np.argwhere(train_label == 1), 0],
    train_data[np.argwhere(train_label == 1), 1],
    s=5,
    c="g",
    marker="x",
)
# plot the test data
plt.scatter(
    test_x[np.argwhere(test_y < 0.5), 0],
    test_x[np.argwhere(test_y < 0.5), 1],
    s=20,
    c="b",
    marker="o",
)
plt.scatter(
    test_x[np.argwhere(test_y >= 0.5), 0],
    test_x[np.argwhere(test_y >= 0.5), 1],
    s=20,
    c="g",
    marker="o",
)
